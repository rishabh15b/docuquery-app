# ğŸ“„ DocuQuery

**DocuQuery** is a powerful **Retrieval-Augmented Generation (RAG)** application built using **LangChain**, **Streamlit**, and **Ollama**, enabling users to interact with their uploaded PDFs through natural language queries. With advanced AI capabilities, DocuQuery provides accurate answers, summaries, insights, visual highlights, table/chart extraction, and page-wise sentiment analysis.

---

## ğŸš€ Features Implemented

- ğŸ“ **PDF Uploads** â€” Upload one or multiple PDF files for analysis.
- âœ‚ï¸ **Document Chunking** â€” Automatically split large documents into configurable chunks for efficient processing.
- ğŸ“¦ **Vector Store (FAISS)** â€” Embeds document chunks using Ollama embeddings and stores them for retrieval.
- ğŸ’¬ **Question Answering** â€” Ask questions about your documents and receive answers using the Mistral model (Ollama).
- ğŸ¯ **Prompt Routing** â€” Smart prompts are generated based on the intent (e.g., summarization, keyword extraction).
- ğŸ“„ **Source Snippets** â€” Display and highlight the actual document passage used to generate each answer.
- ğŸ–ï¸ **Visual Highlighting** â€” Answer snippets are located and highlighted in the original PDF.
- ğŸ“Š **Table Extraction** â€” Automatically detect and display tables using pdfplumber.
- ğŸ“ˆ **Chart Extraction** â€” Extract embedded charts/images from documents using PyMuPDF.
- ğŸ§  **Sentiment Analysis (Page-wise)** â€” Analyze sentiment for each page using TextBlob with summary and CSV export.
- ğŸ§¼ **Clean Interactive UI** â€” Onboarding experience, emoji-enhanced UX, collapsible sections, and dynamic controls.

---

## ğŸ› ï¸ Tech Stack

- **Python 3.9+**
- **Streamlit** â€” Interactive web app framework.
- **LangChain** â€” RAG pipeline and document chain logic.
- **Ollama** â€” Local model inference (Mistral).
- **FAISS** â€” Fast approximate nearest neighbor search for vector DB.
- **TextBlob** â€” Sentiment analysis.
- **pdfplumber / PyMuPDF** â€” PDF parsing and visual extraction.
- **spaCy** â€” (NER ready, not wired in yet)

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ app.py # Main Streamlit application 
â”œâ”€â”€ utils/ # Utility scripts for core functionalities 
â”‚ â”œâ”€â”€ pdf_loader.py # PDF parsing, metadata, chart & table extraction 
â”‚ â”œâ”€â”€ chunking.py # Document splitting logic 
â”‚ â”œâ”€â”€ vector_store.py # FAISS vector store creation & loading 
â”‚ â”œâ”€â”€ prompt_router.py # Smart query prompt routing 
â”‚ â”œâ”€â”€ rag_chain.py # LangChain QA chain setup with Ollama 
â”‚ â”œâ”€â”€ sentiment_analysis.py# Page-wise sentiment analysis 
â”‚ â”œâ”€â”€ pdf_highlight.py # Visual Q&A: highlight source snippets in PDFs 
â”‚ â”œâ”€â”€ classify.py # (Ready) Document classification via LLM 
â”‚ â”œâ”€â”€ ner.py # (Ready) Named entity recognition using spaCy 
â”œâ”€â”€ uploaded_pdfs/ # Directory for storing uploaded PDF files 
â”œâ”€â”€ my_faiss_index/ # Directory for storing the FAISS vector index 
â””â”€â”€ README.md # Project documentation
```

---

## âš™ï¸ Installation

### Prerequisites
- Python 3.9+
- [Ollama](https://ollama.com) installed and running locally
- Streamlit

### Setup Steps

```bash
# 1. Clone the repo
- git clone https://github.com/rishabh15b/docuquery.git
- cd docuquery

# 2. Set up virtual environment
- python -m venv venv
- source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. Install dependencies
- pip install -r requirements.txt

# 4. Pull the Ollama Mistral model
- ollama pull mistral

# 5. Run the app
- streamlit run app.py

# 6. (In separate terminal) Start Ollama server
- ollama serve

# 7. Open the app in your browser
- Go to http://localhost:8501

---

## ğŸ§  Usage

1. Upload PDFs from the sidebar.
2. Configure chunk size & overlap (optional).
3. Choose optional features: charts, tables, sentiment, highlighting.
4. Ask questions using natural language.
5. View answers with highlighted source, sentiment charts, and extracted data.
6. Download sentiment results (CSV) if enabled.

---

## ğŸŒŸ Current Model: Mistral (via Ollama)

- Runs locally on CPU or GPU
- Supports long-context document Q&A
- Great reasoning performance with low latency
- Ideal for personal or internal use without API keys

---

## ğŸ“Œ Next Up (Planned Features)

- ğŸ” **Named Entity Recognition (NER)** â†’ show people, orgs, etc.
- ğŸ§¾ **Document Classifier** â†’ auto-tag as resume, invoice, research paper
- ğŸ“˜ **Section Summarizer & Navigator** â†’ quick jump to abstract, conclusion
- ğŸŒ **Multilingual Support**
- ğŸ”„ **Model Switching** â†’ Ollama / GPT-4 / Claude
- ğŸ“Š **Dashboard Tabs** â†’ Sentiment, Keywords, Entities, Summary

---

## ğŸ“„ License

- This project is licensed under the MIT License.

---

## ğŸ‘¨â€ğŸ’» Author

- Developed by [Rishabh Balaiwar](https://github.com/rishabh15b). Feel free to reach out for questions or collaboration opportunities!

---

## ğŸ“ Contact

- For support or inquiries, contact me at:
- Email: <rbalaiwar@gmail.com>
- GitHub: [Your GitHub Profile](https://github.com/rishabh15b)

